{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\mine\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('the-verdict.txt','r') as f:\n",
    "    raw_text=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20480"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text=re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n",
    "preprocessed=[i.strip() for i in all_text if i.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1130"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words=sorted(set(preprocessed))\n",
    "vocab_size=len(all_words)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab={v:idx for idx,v in enumerate(all_words)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 2.3 Implementing a simple text tokenizer\n",
    "class SimpleTokenizerV1:\n",
    "    def __init__(self,vocab):\n",
    "        super(SimpleTokenizerV1).__init__()\n",
    "        self.str_to_int=vocab\n",
    "        self.int_to_str={v:k for k,v in vocab.items()}\n",
    "    def encode(self,text):\n",
    "        prepro=re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "        prepro=[item.strip() for item in prepro if item.strip()]\n",
    "        prepro=[item  if item in self.str_to_int else \"<|unk|>\" for item in prepro ]\n",
    "        ids=[self.str_to_int[item] for item in prepro]\n",
    "        return ids\n",
    "    def decode(self,ids):\n",
    "        text=' '.join([self.int_to_str[id] for id in ids])\n",
    "        text=re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)  \n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\" It\\' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer=SimpleTokenizerV1(vocab)\n",
    "text = \"\"\"\"It's the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.\"\"\"\n",
    "\n",
    "ids=tokenizer.encode(text)\n",
    "tokenizer.decode(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1132"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <|unk|> å’Œ <|endoftext|>  [\"<|endoftext|>\", \"<|unk|>\"]\n",
    "all_tokens=sorted(set(preprocessed))\n",
    "all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
    "len(all_tokens)\n",
    "\n",
    "vocab={v:idx for idx,v in enumerate(all_tokens)}\n",
    "len(vocab.items())\n",
    "vocab[\"<|endoftext|>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|unk|>, do you like tea? <|endoftext|> In the sunlit terraces of the <|unk|>.'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"Hello, do you like tea?\"\n",
    "text2 = \"In the sunlit terraces of the palace.\"\n",
    "text=\" <|endoftext|> \".join((text1,text2))\n",
    "text\n",
    "\n",
    "tokenizer=SimpleTokenizerV1(vocab)\n",
    "ids=tokenizer.encode(text)\n",
    "tokenizer.decode(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiktoken version: 0.9.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "import tiktoken\n",
    "print(\"tiktoken version:\", version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('the-verdict.txt','r') as f:\n",
    "    text=f.read()\n",
    "    \n",
    "enc_text=tokenizer.encode(text)\n",
    "len(enc_text)\n",
    "enc_sample=enc_text[50:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:[290, 4920, 2241, 287]\n",
      "y:   [4920, 2241, 287, 257]\n"
     ]
    }
   ],
   "source": [
    "context_size = 4    \n",
    "x=enc_sample[:context_size]\n",
    "y=enc_sample[1:context_size+1]\n",
    "\n",
    "print(f'x:{x}')\n",
    "print(f'y:   {y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contex: established---desired:\n",
      "contex: himself---desired: established\n",
      "contex: in---desired: established himself\n",
      "contex: a---desired: established himself in\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,context_size+1):\n",
    "    context=enc_sample[i]\n",
    "    desired=enc_sample[1:i]\n",
    "    print('contex:{0:}---desired:{1:}'.format(tokenizer.decode([context]),tokenizer.decode(desired)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 2.5 A dataset for batched inputs and targets\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        ids=tokenizer.encode(txt)\n",
    "        self.x,self.y=[],[]\n",
    "        \n",
    "        for i in range(0,len(ids)-max_length,stride):\n",
    "            context=ids[i:i+max_length]\n",
    "            desire=ids[i+1:i+max_length+1]\n",
    "            \n",
    "            self.x.append(torch.tensor(context))\n",
    "            self.y.append(torch.tensor(desire))\n",
    "    def __getitem__(self,idx):\n",
    "        return self.x[idx],self.y[idx]\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 2.6 A data loader to generate batches with input-with pairs\n",
    "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
    "                         stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
    "    tokenizer=tiktoken.get_encoding('gpt2')\n",
    "    dataset=GPTDatasetV1(txt,tokenizer,max_length,stride)\n",
    "    \n",
    "    return DataLoader(dataset,batch_size=batch_size,shuffle=True,num_workers=num_workers,drop_last=drop_last)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = create_dataloader_v1(raw_text, batch_size=1, max_length=4, stride=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  502,    11, 12704,   257]])\n",
      "tensor([[   11, 12704,   257,  1310]])\n"
     ]
    }
   ],
   "source": [
    "for x,y in dataloader:\n",
    "    print(x)\n",
    "    print(y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=4, stride=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 257, 9254,  286,  922],\n",
       "         [4544, 9325,  701,    8],\n",
       "         [ 607, 5229,  338, 1243],\n",
       "         [ 606,  477, 1497, 2845],\n",
       "         [3940,  416,  262, 1807],\n",
       "         [ 373, 9675,  379,  717],\n",
       "         [3088,  617,  286,  616],\n",
       "         [ 290, 8104,  465, 1021]]),\n",
       " tensor([[ 9254,   286,   922,    12],\n",
       "         [ 9325,   701,     8,   373],\n",
       "         [ 5229,   338,  1243,    13],\n",
       "         [  477,  1497,  2845,   530],\n",
       "         [  416,   262,  1807,    25],\n",
       "         [ 9675,   379,   717,    11],\n",
       "         [  617,   286,   616, 49025],\n",
       "         [ 8104,   465,  1021,   319]])]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch=next(iter(dataloader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mine",
   "language": "python",
   "name": "mine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
